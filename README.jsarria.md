Name
-------------

- Added decoder for testing on toy data
    - Had to modify models.py to gather proper probability value from phrase table (in toy/phrase-table/phrase_table.out)
- Added score-reranker.py as score-bleu in the decoder directory as well as bleu.py.
    - It prints out the bleu value fo the translation from the test set
- Added capability of opening gzip files
- Large LM does not contain <unk>. So I used the tiny lm value
- Tested getting a bleu score with just the decoder with the test data that was provided. Tried combining TM features for
    different scores (all compared to "test/all.cn-en.en1")
    - Using feature 1, the score was 0.0343661173749
    - Using feature 0, 1, 2, 3, the score was 0.0263737238544
    - Using feature 1 and 3, the score was 0.0173504179269
    - Using feature 0 and 2, the score was 0.0323154901225
    - Using feature 0, 1, and 2, the score was 0.0560581152049
    - Using features 0 and 1, the score was 0.0553584313736
    - Using features 1 and 2, the score was 0.042098894519
- Changed decoder to return n number of of top decoded sentences from last stack. Also changed it so that it can be
  more modular.
- Changed decoder to be able to use weights with its feature functions.
- Changed reranker's learn script to be more modular and to accept the nbest list generated by the decoder.
- Created a main.py that runs a feedback loop by having the decoder generate a list of n best translations per sentence,
  and then use it to generate weights using the reranker which are then used by the decoder to generate a new list of
  best translations
- main.py was run with the decoder finding an top 10 best translations based on a k = 20 translation model. It used
  features 0,1, and 2 as determined above. The result was not much higher than using decoder alone (0.0584620792875)